------------------------- Documentacion ------------------

    Se clonó el repositorio de Universal Robots. 
    Se crearon los controladores de ROS Control. 
    (2 h) --> (fin de semana de primera tutoria)
    
    Se probó a hacer el control cartesiano con la Robotic Toolbox de Peter Corke en Python, pero no acabó de funcionar porque no se calculaban bien
las inversas, los valores no eran del todo correctas. Aunque se le indicaba que fuera en la dirección positiva del eje X, las otras posiciones variaban
    Se configuró un paquete de MoveIT para el UR5, así se consigue incorporar el planificador de trayectorias (o coger de ahí las posiciones finales)
Se añadió el launch demo.launch de la carpeta launch de ur_moveit para ello. Además se cambió el nombre del robot_state_publisher del launch que lanzaba
el robot (más concretamente el tag de "name") para que no interfiera con el del move_group
    Luego, se vio que esto no era óptimo, pues se tenían dos modelos paralelos, lo cual resultaría ineficiente. Por lo tanto, se mantuvo un solo 
robot_state_publisher, desde donde el move_group pueda calcular las trayectorias.
    Al final, el objetivo del move_group es calcular las cinemática inversa del robot, por lo que se va a intentar coger siempre el último elemento.
Los incrementos de posición no serán muy grandes por lo que las trayectorias no deberían tardar mucho en calcularse. Además, se pueden establecer saltos
grandes o incluso calcular el salto de posición respecto a al actual y ponerlo en el planning, para que solo salga un elemento, el final
    En cuanto al Phantom, se han visitado las webs para la instalación de los drivers y paquetes necesarios para leer los datos de este.
    (4 h) --> 13 / 11 / 22
    

    Finalmente, al probar el framework de MoveIT se comprobó que este acercamiento no era el adecuado (todo esto con un programa que reaccione a las 
pulsaciones del teclado), ya que las trayectorias que se calculaban no eran correctas; al poner intervalos muy cortos el robot adoptaba 
configuraciones erráticas para alcanzarlos. Además, no siempre se cnoseguía planificar el 100% de la trayectoria. 
    Volviendo al método en el que se usa la Robotic Toolbox, se cambió el orden en el que se multiplicaban la matriz de transformación actual con la
del desplazamiento (poniendo primero la del desplazamiento), con lo que finalmente si que se conseguía moverse en las direcciones indicadas. Esto es
por el orden de las operaciones, al hacerlo de la manera original se variaban los valores del desplazamiento con las rotaciones de la matriz de 
rotación dentro de la transformada homogénea. 
    Una vez se tenía un movimiento correcto, se probó a hacer la teleoperación con las teclas del teclado, moviendo el robot en cada eje por separado,
además de actuar sobre los ángulos RPY del robot. El programa está hecho entorno a una función de ámbito privado (move) que recibe una matriz de
transformación homogénea y mueve el robot a la posición deseada con la orientación requerida. 
    Para la aplicación real, se tendría que usar unos suscriptores para escuchar los valores del dispositivo háptico Phantom Omni, de manera que a 
cada iteración se modifique la posición del robot. De los topics se recobiría (presumiblemente) un mensaje tipo geometry_msgs/Pose, con lo que se
podría usar la Robotic Toolbox de Python para crear una matriz de transformación homogénea. La mayoría de métodos y atributos se han declarado como
privados
    Con todo, habría que tener cuidado tanto con la frecuencia de envío de datos desde el Phantom (el programa no se debe de interrumpir en exceso, 
se tendrían datos irrelevantes que estarían consumiendo ancho de banda, ...) como con la presencia de singularidades en el control (lo que podría
llevar a situaciones imprevisibles fuera del espacio de trabajo o en configuraciones imposibles, como superposición de eslabones). Esto último se
podría solucionar con el cálculo y monitorización de la manipulabilidad, del determinante de la jacobiana o mediante el establecimiento de límites
articulares para cada una de las articualciones.
    (6 h) --> 14 / 11 / 22

    Se ha cambiado la función para la inversa (de ikine_LM a ikine_LM) ya que esta última la obtiene más rápido (10 veces más rápido). 
    Se ha eliminado el elemento del Rate, que se usaba para poner a dormir al sistema cada vez que se publicaba un mensaje en los commands, 
retrasaba mucho la ejecución y su presencia no era determinante.
    Se ha cambiado el método por el cual se cierra el bucle; ya no se coge del modelo de MoveIT sino que se cogen directamente del modelo de Gazebo
mediante los topics ".../state"
    Se está usando la herramienta "time" para mirar el tiempo que tardan las ejecuciones. 
    Se ha creado la función del callback, para que reciba un mensaje tipo Pose y pase los comandos al robot.
    Se han ajustado los valores de los controladores, ya que en la simulacion, cuando se le enviaban comandos de posicion a cada una de las 
articualciones, el robot oscilaba mucho (sobretodo con las últimas tres, que tenían valores muy bajos). El ajuste se consiguió moviendo el robot
en cartesiano y viendo como reaccionaban a los cambios. En función del comportamiento, se aumentaba la ganancia proporcional o derivativa (la
integral no se usa, ya que en teleoperación introduciría retardos en la ejecución). El caso más crítico era el de la sexta articulación (el 
wrist_3) que vibraba demasiado; esto se debía a que tenía demasiada ganancia, tanto derivativa como proporcional, por lo que se llegó a la conclusión
que, para una articulación tan pequeña solo bastaba componente proporcional --> Esta actividad ha sido llevada a cabo mediante el framework de ROS
llamado RQT.
    (3 h) --> 16 / 11 / 22


    Se ha buscado el repositorio de RobotIQ para descargar los modelos URDF de los manipuladores que hay en el laboratorio y con los que se va a trabajar a la hora del robot real. 
Los modelos del repositorio original no se consiguieron fusionar con el modelo del robot (con el comando "connected on" no funcionaba). Por ello, se buscaron tutoriales y documentación
para unir dos modelos URDF. Finalmente, se encontró uno para añadirlo al modelo aunque no sea del repositorio oficial. 
    (2 h) --> 18 / 11 / 22


    Para añadir la pinza se deben hacer algunas modificaciones en los archivos URDF del repositorio ofifcial de RobotIQ. Las primeras pruebas se 
hicieron basándose en un tutorial en el que se cogía una pinza de tres dedos, pero al colocarla en el modelo se observaban muchas oscilaciones e
impreciosiones en el control incluso del brazo UR5. Se estima que lo que puede causar este fenómeno es la colisión entre los elementos físicos de
la simulacion. Por ello se intentó añadir otra pinza, la robotiq_2F_140 (una pinza con dos dedos)
    Este otro modelo era más complicado y en un inicio no se tenía claro como incluirla directamente. Se lanzó uno de los archivos launch para 
visualizar la pinza y ver que "links" tenía; si se quiere añadir el modelo de la pinza al modelo del brazo se tiene que crear una "joint" que tenga
como "parent" al efector final del brazo y como "child" a la base o conector de la pinza. Este segundo elemento era el que se estaría buscando al
lanzar este launch.
    El archivo que se lanzó fue el "roslaunch robotiq_2f_140_gripper_visualization test_robotiq_arg_2f_140_model.launch", donde se lanza un entorno
en RVIZ con la pinza. Ahí, en la pestaña de "Links" se fueron eliminando hasta que se identificó el conector, con el nombre "robotiq_arg2f_140". Luego
se vio cual era el fichero URDF que se estaba importando dentro del archivo .launch, el cual es el "robotiq_arg2f_140_model.xacro". En ese fichero,
se declara una MACRO de otro XACRO (EXPLICAR QUE SON LOS ARCHIVOS .XACRO), una que se importa desde el fichero "robotiq_arg2f_140_model_macro.xacro"
    El último fichero mencionado es un conjunto de macros que conforman la pinza de dos dedos RobotIQ 2F 140. Al final del fichero es donde se
encuentra la macro correspondiente al conector, que a su vez define en otra fichero de macros .xacro, el "robotiq_arg2f.xacro".
    Una vez llegados a este punto, se hicieron pruebas para intentar añadir la pinza al modelo URDF del robot UR5 de la carpeta "/ur_description/
urdf/ur5_robot.urdf.xacro". Lo primero que se hizo fue intentar eliminar todas las sub-macros que definen cada "joint" y "link", pero daba errores
por las diferentes referencias a otros ficheros y macros. Seguir por este camino implicaría conocer en profundidad el funcionamiento de los ficheros
tipo XACRO, por lo que se optó por otra opción. En el fichero "robotiq_arg2f_140_model.xacro" se definía un parámetro para la macro "robotiq_arg2f_140",
por lo que añadió otro parámetro, el "parent" de la pinza. Luego, en el archivo "robotiq_arg2f.xacro", en la macro de "robotiq_arg2f_base_link" se 
añadió una "joint" de tipo "fixed" junto con un parámetro más, de manera que el "parent" sería ese nuevo parámetro y el "child" el propio "link" 
que se define dentro de esa misma MACRO.
    Así, haciendo un "include" de "robotiq_arg2f_140_model_macro.xacro" en el archivo "ur5_robot.urdf.launch" especificando como parámetro del
"robotiq_arg2f_140" el link "ee_link" o "tool0" del UR5 se consigue añadir la pinza al modelo de Gazebo. Al lanzar el launch tal cual está, se 
importa el modelo, pero se lanza un error, ya que hay "joints" que no tienen controlador, con lo que se va a proceder a añadirlo.
    
    Lo primero que habría que hacer es comprobar que tipo de transmisiones en las "joints" viene por defecto en los paquetes de RobotIQ. Esta
configuración se declara en el archivo "robotiq_arg2f_transmission.xacro", donde se ver que son de tipo "transmission_interface/SimpleTransmission"
con el "hardwareInterface" configuado como "PositionJointInterface", lo que resulta no correcto para el control que se está realizando (un control en
posición del robot y la pinza), lo correcto sería que fueran interfaces de esfuerzo (EffotJointInterface). Así, se puede definir mediante 
ROS - Control controladores de posición para cada una de las articulaciones de la pinza, el nombre de las cuales se puede ver en la interfaz 
de usuario de Gazebo (navegando por el menú de la derecha y accediendo al apartado de "joints") o buscando las definiciones de "joint" en el 
archivo "robotiq_arg2f_140_model_macro.xacro".
    Al crear los controladores se observó que daba errores al cargarlos en la simulación (no detectaba la "joint" en los recursos). Esto se puede 
deber a que no se definen bien las transmisiones en los archivos de MACRO, solamente la del "finger_joint" en el fichero "robotiq_arg2f_transmission".xacro". Solucionar esto requeriría hacer ficheros nuevos de coniguración (nuevas macros) similares a las que se usan en los del UR5, ya que en los .xacro de RobotIQ no se hacen como se está utilizando en el proyecto.
Otra opción sería ejecutarlo, o generar un controlador adecuado a los ficheros de RobotIQ. Al final, se tomó la primera solución; dentro del fichero
.xacro de las transmisiones se definieron todas las hardwareInterface de todas las "joints", definiéndolas como EffotJointInterface. 
    Por otro lado, se definieron los valores de las ganancias PID de los controladores de cada articulación de la pinza con una estructura similar 
a la del controlador del brazo. Las ganancias se definen con valores muy bajos, pues son articulaciones pequeñas y aún se tienen que ajustar en 
este momento. Por lo tanto, en el archivo .launch se carga el controlador con un "controller_manager" con un nombre diferente.
    Luego, al lanzar la simulación se observaba que se cargaba el modelo, pero la pinza no tenía colisión y estaba mal colocada en el último eslabón
del UR5. El primer problema se solucuionó añdadiendo unos comandos en el fichero "robotiq_arg2f_140_model_macro.xacro" donde se activa la colisión
de los elementos "link" en la simulación de Gazebo. Luego, se cambió el parámetro "parent" que se le daba en el fichero "ur5_robot.urdf.xacro", de
"ee_link" a "tool0", para que esté alineado con el robot. Después, se lanzó la simulación y se probó a mover el robot para comprobar que lo hacía
con normalidad. Además, se ha cambiado el origen de la unión entre la pinza y el efector final del robot para evitar que esté uno metido dentro del
otro, lo que provoca que estén colisionando constantemente, lo que da lugar a vibraciones o clipeos.
    (5 h) --> 20 / 11 / 22


    Se ha creado un fichero de Python a modo de controlador en velocidad, aunque no se ha especificado ningún controlador de este tipo, sino que se toma
un controlador en posición al que se le pasan los diferenciales que se reciben desde el dispositivo de control. De esta manera, se tiene la misma 
estructura que con el controlador anterior pero con un bucle infinito de control. En éste, se va aumentando el valor de un vector de incrementos 
([x, y, z, roll, pitch, yaw]) según los valores que se reciben desde un topic conectado a la interfaz (ya sea el Phantom o una interfaz propia). Se
calcula la matriz de transformación homogénea del incremento (de momento solo se controlan los tres primeros grados de libertad) y se multiplica por
la matriz de transformación actual. La matriz resultado de esta operación se envía como parámetro a la función que se encarga de mover el robot 
(publicar en el topic de las articulaciones y hacer la cinemática inversa).
    Por otro lado, se ha añadido un fichero .launch a los que ya habían presentes, uno cuya finalidad es la de cargar dos robots al mundo Gazebo de
la simulación, incluyendo el fichero ur5.launch dos veces en distintos espacios de nombres (ns). Las modificaciones se han realizado sobre el launch
original del ur5, donde se han eliminado los arugumentos, así como el spawner del mundo de Gazebo; si este comando estuviera dentro de ur5.launch
se cargarían dos mundos diferentes, sin posibilidad de interactuar entre ellos. Luego, se argumentan varios parámetros que se le pasan al fichero, uno
que correspondería con el nombre del robot (ur5_1 o ur5_2), ya que el simulador no es capaz de cargar dos modelos que se llamen igual. Además de que
se definien posiciones distintas para los dos robots medante otro argumento siguiendo el formato del spawner del modelo del robot en Gazebo.
    (2.5 h) --> 25 / 11 / 22


    En esta sesión, lo primero que se ha intentado hacer es conceguir que la pinza se importe correctamente a la simulación; según viene en el
repositorio de RobotIQ, no se importa bien en Gazebo. Las articulaciones en los modelos DAE no tienen agujeros, por lo que se tienen que definir 
joints en los ficheros de configuración URDF. En el que viene por defecto haría falta definir una, la que une el inner_finger con el inner_knuckle
de cada uno de los dedos de la pinza. Definirla manualmente es complicado, pues habría que definir la posición de la joint y hacerlo es difícil a 
la vez que no resultaría preciso del todo. Así, buscando en algunos repositorios se encontró que si se definían las joints como un grupo de movimiento
coordinado entre ellos, se puede corregir y que se muestren bien todas ellas. Esta modificación se introduce en el fichero de transmissions del
gripper 140 2F. Esta solución consigue que se vea bien en la simulación, aunque no permite el control directamente con ROS-Control (las joints 
están fijas), por lo que se va a optar por la planificación de trayectorias con MoveIT, ya que solo se requerirían de dos movimientos; abrir y 
cerrar, que se definirían previamente.
    Luego, se pasó a hacer un controlador en velocidad. Al importarlo tal cual en la simulación se observó que el robot caía por su propio peso,
esto se debía a que, al ser en velocidad, al principio no recibe comandos de velocidad por lo que el motor no tiene que mantener ninguna referencia
de entrada. Si no está preparado o configurado para mantener posición, el motor se suelta y deja ir la articulación. Por lo tanto, la solución que se
ha elegido es la de crear un script de Pyhton, un nodo, cuya función sea la de mantener la velocidad del motor aun cuando no recibe comandos de 
movimiento; el procedimiento es el siguiente: se recogen los datos del joint_state_publisher de cada una de las articualciones, el process_value 
(valor_actual) y el set_point (el comando que se le envía a la articulación desde el topic de .../command). Una vez se tienen cada uno de ellos, se
ejerce un control en bucle cerrado, donde se calcula el error en velocidad (set_point - process_value) y este se envía al controlador articular en
velocidad de cada articualción. Al principio, el robot oscilaba mucho y no se conseguía mantener bien la posición, debido a que los valores PID de
los controladores articulares eran incorrectos. De esta manera, se procedió a ajustarlos, primero modificándolos en el .yaml y relanzando la
simulación (el robot se caía al suelo y no se podía ver con claridad su funcionamiento) y luego mediante RQT y el plugin de Dynamic Reconfigure, 
ajustando los valores de ganancia PID. Generalmente, se seleccionaron controladores PD, con valores bajos del apartado derivativo. Respecto a las
magnitudes proporcionales, son bastante más bajas que las del controlador en posición, aunque en este punto se tienen que ajustar del todo, ya que 
el robot vibra y no se ha comprobado su comportamiento ante el control en velocidad externo; aquí solo se mantiene sin caerse.
    (4 h) --> 29 / 11 / 22

    Se ha ido comprobando el  comportamiento del controlador en velocidad del bucle cerrado. Se observó que, aunque mantenía la velocidad de las
articulaciones, no se conseguía que al mandarle mensajes de movimiento los hiciera correctamente. Esto es debido a que está intentando mantener el
set_point del joint_state, que puede no estar coordinado con la publicación del command, por lo que hay veces que se publica la velocidad deseada
pero el controlador intenta mantener la velocidad inicial (0.0 en este caso). 
    Se intentó crear topics adicionales con los que mandar la velocidad para no indicarla directamente en el commando pero seguí surgiendo el 
mismo problema. Hasta aquí se intentaba hacer un enfoque asíncrono; no se coordinan los envíos de mensajes (lo que es erróneo). Así, haciendo pruebas,
se vio que en el callback del joint_state, si se le suma la velocidad deseada a la variable que almacena el set_point, se consigue la velocidad que 
se indica, al menos con la primera articulación. Así, la ejecución se haría de manera síncrona, pues los comandos de movimiento que presumiblemente
se mandarían desde otro topic tendrían que esperar a que se recibiera mensajes desde el joint_state_publisher del robot.
    ###################################### [PENDIENTE DE PRUEBA CON TODAS LAS ARTICULACIONES] ##########################################
    (1 h) --> 30 / 11 / 22


    PROBAR CADA UNA DE LOS CONTROLADORES POR SEPARADO, DANDOLE VALORES CON RQT TOPIC

