------------------------- Documentacion ------------------

    Se clonó el repositorio de Universal Robots. 
    Se crearon los controladores de ROS Control. 
    (2 h) --> (fin de semana de primera tutoria)
    
    Se probó a hacer el control cartesiano con la Robotic Toolbox de Peter Corke en Python, pero no acabó de funcionar porque no se calculaban bien
las inversas, los valores no eran del todo correctas. Aunque se le indicaba que fuera en la dirección positiva del eje X, las otras posiciones variaban
    Se configuró un paquete de MoveIT para el UR5, así se consigue incorporar el planificador de trayectorias (o coger de ahí las posiciones finales)
Se añadió el launch demo.launch de la carpeta launch de ur_moveit para ello. Además se cambió el nombre del robot_state_publisher del launch que lanzaba
el robot (más concretamente el tag de "name") para que no interfiera con el del move_group
    Luego, se vio que esto no era óptimo, pues se tenían dos modelos paralelos, lo cual resultaría ineficiente. Por lo tanto, se mantuvo un solo 
robot_state_publisher, desde donde el move_group pueda calcular las trayectorias.
    Al final, el objetivo del move_group es calcular las cinemática inversa del robot, por lo que se va a intentar coger siempre el último elemento.
Los incrementos de posición no serán muy grandes por lo que las trayectorias no deberían tardar mucho en calcularse. Además, se pueden establecer saltos
grandes o incluso calcular el salto de posición respecto a al actual y ponerlo en el planning, para que solo salga un elemento, el final
    En cuanto al Phantom, se han visitado las webs para la instalación de los drivers y paquetes necesarios para leer los datos de este.
    (4 h) --> 13 / 11 / 22
    

    Finalmente, al probar el framework de MoveIT se comprobó que este acercamiento no era el adecuado (todo esto con un programa que reaccione a las 
pulsaciones del teclado), ya que las trayectorias que se calculaban no eran correctas; al poner intervalos muy cortos el robot adoptaba 
configuraciones erráticas para alcanzarlos. Además, no siempre se cnoseguía planificar el 100% de la trayectoria. 
    Volviendo al método en el que se usa la Robotic Toolbox, se cambió el orden en el que se multiplicaban la matriz de transformación actual con la
del desplazamiento (poniendo primero la del desplazamiento), con lo que finalmente si que se conseguía moverse en las direcciones indicadas. Esto es
por el orden de las operaciones, al hacerlo de la manera original se variaban los valores del desplazamiento con las rotaciones de la matriz de 
rotación dentro de la transformada homogénea. 
    Una vez se tenía un movimiento correcto, se probó a hacer la teleoperación con las teclas del teclado, moviendo el robot en cada eje por separado,
además de actuar sobre los ángulos RPY del robot. El programa está hecho entorno a una función de ámbito privado (move) que recibe una matriz de
transformación homogénea y mueve el robot a la posición deseada con la orientación requerida. 
    Para la aplicación real, se tendría que usar unos suscriptores para escuchar los valores del dispositivo háptico Phantom Omni, de manera que a 
cada iteración se modifique la posición del robot. De los topics se recobiría (presumiblemente) un mensaje tipo geometry_msgs/Pose, con lo que se
podría usar la Robotic Toolbox de Python para crear una matriz de transformación homogénea. La mayoría de métodos y atributos se han declarado como
privados
    Con todo, habría que tener cuidado tanto con la frecuencia de envío de datos desde el Phantom (el programa no se debe de interrumpir en exceso, 
se tendrían datos irrelevantes que estarían consumiendo ancho de banda, ...) como con la presencia de singularidades en el control (lo que podría
llevar a situaciones imprevisibles fuera del espacio de trabajo o en configuraciones imposibles, como superposición de eslabones). Esto último se
podría solucionar con el cálculo y monitorización de la manipulabilidad, del determinante de la jacobiana o mediante el establecimiento de límites
articulares para cada una de las articualciones.
    (6 h) --> 14 / 11 / 22

    Se ha cambiado la función para la inversa (de ikine_LM a ikine_LM) ya que esta última la obtiene más rápido (10 veces más rápido). 
    Se ha eliminado el elemento del Rate, que se usaba para poner a dormir al sistema cada vez que se publicaba un mensaje en los commands, 
retrasaba mucho la ejecución y su presencia no era determinante.
    Se ha cambiado el método por el cual se cierra el bucle; ya no se coge del modelo de MoveIT sino que se cogen directamente del modelo de Gazebo
mediante los topics ".../state"
    Se está usando la herramienta "time" para mirar el tiempo que tardan las ejecuciones. 
    Se ha creado la función del callback, para que reciba un mensaje tipo Pose y pase los comandos al robot.
    Se han ajustado los valores de los controladores, ya que en la simulacion, cuando se le enviaban comandos de posicion a cada una de las 
articualciones, el robot oscilaba mucho (sobretodo con las últimas tres, que tenían valores muy bajos). El ajuste se consiguió moviendo el robot
en cartesiano y viendo como reaccionaban a los cambios. En función del comportamiento, se aumentaba la ganancia proporcional o derivativa (la
integral no se usa, ya que en teleoperación introduciría retardos en la ejecución). El caso más crítico era el de la sexta articulación (el 
wrist_3) que vibraba demasiado; esto se debía a que tenía demasiada ganancia, tanto derivativa como proporcional, por lo que se llegó a la conclusión
que, para una articulación tan pequeña solo bastaba componente proporcional --> Esta actividad ha sido llevada a cabo mediante el framework de ROS
llamado RQT.
    (3 h) --> 16 / 11 / 22


    Se ha buscado el repositorio de RobotIQ para descargar los modelos URDF de los manipuladores que hay en el laboratorio y con los que se va a trabajar a la hora del robot real. 
Los modelos del repositorio original no se consiguieron fusionar con el modelo del robot (con el comando "connected on" no funcionaba). Por ello, se buscaron tutoriales y documentación
para unir dos modelos URDF. Finalmente, se encontró uno para añadirlo al modelo aunque no sea del repositorio oficial. 
    (2 h) --> 18 / 11 / 22


    Para añadir la pinza se deben hacer algunas modificaciones en los archivos URDF del repositorio ofifcial de RobotIQ. Las primeras pruebas se 
hicieron basándose en un tutorial en el que se cogía una pinza de tres dedos, pero al colocarla en el modelo se observaban muchas oscilaciones e
impreciosiones en el control incluso del brazo UR5. Se estima que lo que puede causar este fenómeno es la colisión entre los elementos físicos de
la simulacion. Por ello se intentó añadir otra pinza, la robotiq_2F_140 (una pinza con dos dedos)
    Este otro modelo era más complicado y en un inicio no se tenía claro como incluirla directamente. Se lanzó uno de los archivos launch para 
visualizar la pinza y ver que "links" tenía; si se quiere añadir el modelo de la pinza al modelo del brazo se tiene que crear una "joint" que tenga
como "parent" al efector final del brazo y como "child" a la base o conector de la pinza. Este segundo elemento era el que se estaría buscando al
lanzar este launch.
    El archivo que se lanzó fue el "roslaunch robotiq_2f_140_gripper_visualization test_robotiq_arg_2f_140_model.launch", donde se lanza un entorno
en RVIZ con la pinza. Ahí, en la pestaña de "Links" se fueron eliminando hasta que se identificó el conector, con el nombre "robotiq_arg2f_140". Luego
se vio cual era el fichero URDF que se estaba importando dentro del archivo .launch, el cual es el "robotiq_arg2f_140_model.xacro". En ese fichero,
se declara una MACRO de otro XACRO (EXPLICAR QUE SON LOS ARCHIVOS .XACRO), una que se importa desde el fichero "robotiq_arg2f_140_model_macro.xacro"
    El último fichero mencionado es un conjunto de macros que conforman la pinza de dos dedos RobotIQ 2F 140. Al final del fichero es donde se
encuentra la macro correspondiente al conector, que a su vez define en otra fichero de macros .xacro, el "robotiq_arg2f.xacro".
    Una vez llegados a este punto, se hicieron pruebas para intentar añadir la pinza al modelo URDF del robot UR5 de la carpeta "/ur_description/
urdf/ur5_robot.urdf.xacro". Lo primero que se hizo fue intentar eliminar todas las sub-macros que definen cada "joint" y "link", pero daba errores
por las diferentes referencias a otros ficheros y macros. Seguir por este camino implicaría conocer en profundidad el funcionamiento de los ficheros
tipo XACRO, por lo que se optó por otra opción. En el fichero "robotiq_arg2f_140_model.xacro" se definía un parámetro para la macro "robotiq_arg2f_140",
por lo que añadió otro parámetro, el "parent" de la pinza. Luego, en el archivo "robotiq_arg2f.xacro", en la macro de "robotiq_arg2f_base_link" se 
añadió una "joint" de tipo "fixed" junto con un parámetro más, de manera que el "parent" sería ese nuevo parámetro y el "child" el propio "link" 
que se define dentro de esa misma MACRO.
    Así, haciendo un "include" de "robotiq_arg2f_140_model_macro.xacro" en el archivo "ur5_robot.urdf.launch" especificando como parámetro del
"robotiq_arg2f_140" el link "ee_link" o "tool0" del UR5 se consigue añadir la pinza al modelo de Gazebo. Al lanzar el launch tal cual está, se 
importa el modelo, pero se lanza un error, ya que hay "joints" que no tienen controlador, con lo que se va a proceder a añadirlo.
    
    Lo primero que habría que hacer es comprobar que tipo de transmisiones en las "joints" viene por defecto en los paquetes de RobotIQ. Esta
configuración se declara en el archivo "robotiq_arg2f_transmission.xacro", donde se ver que son de tipo "transmission_interface/SimpleTransmission"
con el "hardwareInterface" configuado como "PositionJointInterface", lo que resulta no correcto para el control que se está realizando (un control en
posición del robot y la pinza), lo correcto sería que fueran interfaces de esfuerzo (EffotJointInterface). Así, se puede definir mediante 
ROS - Control controladores de posición para cada una de las articulaciones de la pinza, el nombre de las cuales se puede ver en la interfaz 
de usuario de Gazebo (navegando por el menú de la derecha y accediendo al apartado de "joints") o buscando las definiciones de "joint" en el 
archivo "robotiq_arg2f_140_model_macro.xacro".
    Al crear los controladores se observó que daba errores al cargarlos en la simulación (no detectaba la "joint" en los recursos). Esto se puede 
deber a que no se definen bien las transmisiones en los archivos de MACRO, solamente la del "finger_joint" en el fichero "robotiq_arg2f_transmission".xacro". Solucionar esto requeriría hacer ficheros nuevos de coniguración (nuevas macros) similares a las que se usan en los del UR5, ya que en los .xacro de RobotIQ no se hacen como se está utilizando en el proyecto.
Otra opción sería ejecutarlo, o generar un controlador adecuado a los ficheros de RobotIQ. Al final, se tomó la primera solución; dentro del fichero
.xacro de las transmisiones se definieron todas las hardwareInterface de todas las "joints", definiéndolas como EffotJointInterface. 
    Por otro lado, se definieron los valores de las ganancias PID de los controladores de cada articulación de la pinza con una estructura similar 
a la del controlador del brazo. Las ganancias se definen con valores muy bajos, pues son articulaciones pequeñas y aún se tienen que ajustar en 
este momento. Por lo tanto, en el archivo .launch se carga el controlador con un "controller_manager" con un nombre diferente.
    Luego, al lanzar la simulación se observaba que se cargaba el modelo, pero la pinza no tenía colisión y estaba mal colocada en el último eslabón
del UR5. El primer problema se solucuionó añdadiendo unos comandos en el fichero "robotiq_arg2f_140_model_macro.xacro" donde se activa la colisión
de los elementos "link" en la simulación de Gazebo. Luego, se cambió el parámetro "parent" que se le daba en el fichero "ur5_robot.urdf.xacro", de
"ee_link" a "tool0", para que esté alineado con el robot. Después, se lanzó la simulación y se probó a mover el robot para comprobar que lo hacía
con normalidad. Además, se ha cambiado el origen de la unión entre la pinza y el efector final del robot para evitar que esté uno metido dentro del
otro, lo que provoca que estén colisionando constantemente, lo que da lugar a vibraciones o clipeos.
    (5 h) --> 20 / 11 / 22


    Se ha creado un fichero de Python a modo de controlador en velocidad, aunque no se ha especificado ningún controlador de este tipo, sino que se toma
un controlador en posición al que se le pasan los diferenciales que se reciben desde el dispositivo de control. De esta manera, se tiene la misma 
estructura que con el controlador anterior pero con un bucle infinito de control. En éste, se va aumentando el valor de un vector de incrementos 
([x, y, z, roll, pitch, yaw]) según los valores que se reciben desde un topic conectado a la interfaz (ya sea el Phantom o una interfaz propia). Se
calcula la matriz de transformación homogénea del incremento (de momento solo se controlan los tres primeros grados de libertad) y se multiplica por
la matriz de transformación actual. La matriz resultado de esta operación se envía como parámetro a la función que se encarga de mover el robot 
(publicar en el topic de las articulaciones y hacer la cinemática inversa).
    Por otro lado, se ha añadido un fichero .launch a los que ya habían presentes, uno cuya finalidad es la de cargar dos robots al mundo Gazebo de
la simulación, incluyendo el fichero ur5.launch dos veces en distintos espacios de nombres (ns). Las modificaciones se han realizado sobre el launch
original del ur5, donde se han eliminado los arugumentos, así como el spawner del mundo de Gazebo; si este comando estuviera dentro de ur5.launch
se cargarían dos mundos diferentes, sin posibilidad de interactuar entre ellos. Luego, se argumentan varios parámetros que se le pasan al fichero, uno
que correspondería con el nombre del robot (ur5_1 o ur5_2), ya que el simulador no es capaz de cargar dos modelos que se llamen igual. Además de que
se definien posiciones distintas para los dos robots medante otro argumento siguiendo el formato del spawner del modelo del robot en Gazebo.
    (2.5 h) --> 25 / 11 / 22


    En esta sesión, lo primero que se ha intentado hacer es conceguir que la pinza se importe correctamente a la simulación; según viene en el
repositorio de RobotIQ, no se importa bien en Gazebo. Las articulaciones en los modelos DAE no tienen agujeros, por lo que se tienen que definir 
joints en los ficheros de configuración URDF. En el que viene por defecto haría falta definir una, la que une el inner_finger con el inner_knuckle
de cada uno de los dedos de la pinza. Definirla manualmente es complicado, pues habría que definir la posición de la joint y hacerlo es difícil a 
la vez que no resultaría preciso del todo. Así, buscando en algunos repositorios se encontró que si se definían las joints como un grupo de movimiento
coordinado entre ellos, se puede corregir y que se muestren bien todas ellas. Esta modificación se introduce en el fichero de transmissions del
gripper 140 2F. Esta solución consigue que se vea bien en la simulación, aunque no permite el control directamente con ROS-Control (las joints 
están fijas), por lo que se va a optar por la planificación de trayectorias con MoveIT, ya que solo se requerirían de dos movimientos; abrir y 
cerrar, que se definirían previamente.
    Luego, se pasó a hacer un controlador en velocidad. Al importarlo tal cual en la simulación se observó que el robot caía por su propio peso,
esto se debía a que, al ser en velocidad, al principio no recibe comandos de velocidad por lo que el motor no tiene que mantener ninguna referencia
de entrada. Si no está preparado o configurado para mantener posición, el motor se suelta y deja ir la articulación. Por lo tanto, la solución que se
ha elegido es la de crear un script de Pyhton, un nodo, cuya función sea la de mantener la velocidad del motor aun cuando no recibe comandos de 
movimiento; el procedimiento es el siguiente: se recogen los datos del joint_state_publisher de cada una de las articualciones, el process_value 
(valor_actual) y el set_point (el comando que se le envía a la articulación desde el topic de .../command). Una vez se tienen cada uno de ellos, se
ejerce un control en bucle cerrado, donde se calcula el error en velocidad (set_point - process_value) y este se envía al controlador articular en
velocidad de cada articualción. Al principio, el robot oscilaba mucho y no se conseguía mantener bien la posición, debido a que los valores PID de
los controladores articulares eran incorrectos. De esta manera, se procedió a ajustarlos, primero modificándolos en el .yaml y relanzando la
simulación (el robot se caía al suelo y no se podía ver con claridad su funcionamiento) y luego mediante RQT y el plugin de Dynamic Reconfigure, 
ajustando los valores de ganancia PID. Generalmente, se seleccionaron controladores PD, con valores bajos del apartado derivativo. Respecto a las
magnitudes proporcionales, son bastante más bajas que las del controlador en posición, aunque en este punto se tienen que ajustar del todo, ya que 
el robot vibra y no se ha comprobado su comportamiento ante el control en velocidad externo; aquí solo se mantiene sin caerse.
    (4 h) --> 29 / 11 / 22

    Se ha ido comprobando el  comportamiento del controlador en velocidad del bucle cerrado. Se observó que, aunque mantenía la velocidad de las
articulaciones, no se conseguía que al mandarle mensajes de movimiento los hiciera correctamente. Esto es debido a que está intentando mantener el
set_point del joint_state, que puede no estar coordinado con la publicación del command, por lo que hay veces que se publica la velocidad deseada
pero el controlador intenta mantener la velocidad inicial (0.0 en este caso). 
    Se intentó crear topics adicionales con los que mandar la velocidad para no indicarla directamente en el commando pero seguí surgiendo el 
mismo problema. Hasta aquí se intentaba hacer un enfoque asíncrono; no se coordinan los envíos de mensajes (lo que es erróneo). Así, haciendo pruebas,
se vio que en el callback del joint_state, si se le suma la velocidad deseada a la variable que almacena el set_point, se consigue la velocidad que 
se indica, al menos con la primera articulación. Así, la ejecución se haría de manera síncrona, pues los comandos de movimiento que presumiblemente
se mandarían desde otro topic tendrían que esperar a que se recibiera mensajes desde el joint_state_publisher del robot. Es necesario que el nodo
que ejecuta el controlador en velocidad en bucle cerrado debe iniciarse junto con la simulación, y esta debe estar pausada al lanzarse, para que 
no obtenga valores indeseados al empezar y se caiga.
    (1 h) --> 30 / 11 / 22


    Se ha intentado instalar los drivers para el Phantom Omni en Linux. Para ello, se ha seguido los tutoriales que se ofrecen en la página web de
OpenHaptics. Se crearon las carpetas correspondientes y se realizaron los pasos para conectarse al Phantom mediante Ethernet; se conecta el dispositivo,
se entra en la configuración del ordenador, el apartado "Redes / Network" y se identifica el dispositivo cableado conectado por Ethernet. Luego,
se establece que se conecten localmente. Finalmente se desconecta y conecta el dispositivo al ordenador. 
    Después de segui estos pasos se podía calibrar el Phantom y hacer algunas demos, por lo que el ordenador está recibiendo datos del Phantom. Se
intentó ejecutar algunos de los scripts de OpenHaptics, pero se producían errores de ejecución. De esta manera, se probó a instalar algunos 
proyectos realizados en Linux que hacían uso del Phantom Omni, aunque eran muy antiguos y las versiones tanto de Linux como de ROS incompatibles. 
Además de que se indicaba en todos ellos (y en el oficial también) que no era posible conectar varios Phantom al mismo equipo. Así, se llegó al 
repositorio de jhu, donde se indicaban los pasos para la instalación de los drivers del Phantom en Linux 20.04 (con ROS Noetic). Instalando las 
librerías indicadas y descargando las herramientas de catkin correspondientes a versiones anteriores (especificando python3 como la versión de
Python) se pudo compilar el proyecto en el ordenador propio, solo que había un ejemplo de una de las librería en el directorio src/cisst-saw/sawControllers/examples
en el que se intoducía un paquete que producía errores al compilar por un paquete que no encontraba. Como no se encontró la instalación ni el modo 
de realizarla se decidió desinstalarlo, pues era un ejemplo y no pasaba nada (en principio) si se prescindía de él.
    Por otro lado, se han creado los topic por los que se pasa la posición cartesiana del robot y el índice de manipulabilidad, con el objetivo de
que el nodo de ROS correspondiente al Phantom Omni sea capaz de suscribirse a éstos y ejercer fuerza sobre el operador.
    Finalmente, se ha empezado a hacer el controlador de velocidad en bucle cerrado del robot para que sea capaz de recibir comando de velocidad 
desde otros nodos, y no solo sea capaz de mantener la velocidad actual. Para ello, se crearon varios topics donde se recoje la información articular
de los comandos deseados que se quieren mandar al robot. Luego, esos valores se sumaban en el callback al set_point, para hacerlo de manera síncrona.
Así, se podían mandar mensajes de velocidad, aunque se producían oscilaciones en los movimientos y algunas inestabilidades en unas articualciones
daban comportamientos no deseados en otras (acoplamiento general). Así, se empezó a ajustar las ganancias PID de los controladores articulares
del robot. Ajustando estos valores, se observaron comportamientos menos oscilatorios pero que no eran del todo aceptables para realizar un control
preciso. Lo que ocurría era que el control en bucle cerrado actuaba con una frecuencia demasiado elevada, lo que provocaba que el controlador no 
parara de corregir desviaciones mínimas en las articulaciones. De esta manera, se bajó la frecuencia de funcionamiento del script de Python. Luego,
se aplicó un enfoque más parecido al que se tiene en teoría de control tradicional; hasta ahora se usaba la diferencia entre el punto detectado de la
articulación y el valor que se quiere dar. Ahora, se suma al comando que se manda al robot la posición deseada menos la que actualmente tiene (el 
error). Aun así, el comportamiento era bastante similar, siendo la disminución de la frecuencia el factor determinante para este problema.
    (5 h) --> 31 / 11/ 22


    Se está realizando el control en bucle cerrado en posición a partir del que se hizo del de velocidad, siguiendo los mismos principios. Mientras
se hacía, se encontraron con los mismos problemas que con el de velocidad (sobretodo el problema de la frecuencia). Así, se tuvieron que ajustar los
controladores otra vez, pues se está aplicando otro paradigma de control. En un primer ajuste de los controladores se observó que oscilaban mucho
al detenerse después de realizar un movimiento, por lo que se va a intentar solucionar este problema, aumentando las ganancias proporcionales y 
ajustando la derivativa.
    Para ajustar las ganancias se tiene en cuenta los valores PD en el controlador de posición; el proporcional para disminuir el tiempo de subida del 
sistema (aunque se aumentan las oscilaciones a medida que se incrementa la magnitud) y el derivativo, que amortigua las oscilaciones aunque ralentiza 
el sistema. De esta manera, se intnenta conseguir una actuación lo suficientemente rápida para que se llegue bien a las posiciones de consigna pero 
con pocas oscilaciones (para que cuando no se manden más se mantenga en la posición y no oscile).
    Por otro lado, para el controlador de posición se han ajustado las ganancias del controlador, sobretodo las de la muñeca.
    El problema de la frecuencia ha sido muy importante en ambos controladores; con cambiar la frecuencia de envío de datos así como a la que trabaja el
bucle cerrado se deben cambiar las ganancias del controlador. En RQT, estableciendo una frecuencia de publicación de unos 50 Hz se ajustaron los valores PID.
Aún así, también se aumentó la frecuencia a la que funcionaba el script del control en bucle cerrado.
    (5 h) --> 4 / 12 / 22


    Después de hacer la estructura anterior y ver que era muy complicado hacerla funcionar (demasiadas oscilaciones al detener el mandar los datos),
se dejó como estaba anteriormente, por lo menos en posición. No sería necesario mantener la posición dada pues eso ya lo hace un controlador de
posición por definición, por lo que simplemente se cargan los controladores articulares. En cuanto al controlador de velocidad, se añadió la pinza
al modelo para observar su comportamiento ante una carga en el extremo y se observó que sucedía lo mismo que con los primeros controladores de 
velocidad; el controlador intentaba corregir los errores en velocidad, en este caso producidos por el peso de la pinza, a una frecuencia muy alta,
por lo que el robot temblaba y las articulaciones oscilaban demasiado. Así, en vez de calibrar otra vez las ganancias PID de cada articulación,
se disminuyó la frecuencia de trabajo de los controladores. La misma prueba se hizo con el controlador de posición, aunque este si que conseguía 
mantener los valores de las articualciones con solvencia.
    Por otro lado, se ha resuelto el problema de la pinza. Para ello, se ha buscado un repositorio Github que incluyera el modelo de la pinza en una
simulación de Gazebo. Durante la búsqueda se encontró que todos ellos incorporaban MoveIt en sus proyectos, un enfoque alejado del control directo
que se pretende buscar en este trabajo (MoveIt es un paquete para el control y generación de trayectorias). Aun así, se encontró lo que se buscaba,
una configuración de la pinza que funcionaba en Gazebo; recordar que el porblema era que había una joint que no estaba presente en los archivos de
configuración URDF del fabricante. Esto se solucionó haciendo uso del paquete roboticsgroup_gazebo_plugins. Con esto se puede definir que las 
diferentes joints de la pinza imiten el movimiento de una en específico, la una que se va a mover, siguiendo la geometría y mecansimos implementados.
Además de elegir la dirección del movimiento resultante. Por ejemplo, si la articulación de referencia se mueve en sentido contrario a las agujas del
reloj, la secundaria se podría mover en esa misma dirección en la contraria según se quiera. Una vez se tuvo la pinza dentro de la simulación, se 
definió un controlador mediante ROS-Control. Para poder añadirlo, había que cambiar el tipo de transmisión con el que se importaba la pinza; de
PositionJointInterface a EffortJointInterface. Así, se ajustó el controlador para que cerrara sin provocar oscilaciones que se propagaran al resto
del brazo robótico.
    Además, se ha incrementado la frecuencia a la que funcionan los joint_state_publisher para que la pinza pueda seguir comandos de posición de 
manera más solvente. Al probar con la función seno en RQT se observó que los pasos eran muy bruscos y que daba saltos en vez de seguir una trayectoria
suave. Esto no influyó en los otros controladores, ya que el de posición sigue funcionando correctamente y el de velocidad está saturado por un
script que se asegura de publicar correcciones de velocidad a una frecuencia determinada, de manera que los PID funcionen correctamente.
    Cabe destacar que a veces, al iniciar la simulación, los dedos de la pinza se sueltan y se quedan colgando del robot. De momento no se encontró
explicación a este problema, aunque si se recompila y se actualiza el source (se ejecuta en el terminal "source devel/setup.bash"), al volver a
ejecutar el script de simulación aparece la pinza en el robot de manera correcta.
    (3 h) --> 5 / 12 / 22


    Para compilar todos los paquetes de RobotIq (hasta ahora no se podía compilar entero porque daba errores) se ha detectado que el paquete de
"robotiq_3f_gripper_articulated_gazebo_plugins" es el que produce dichos errores. A la hora de manejar el real no debería haber problemas pues se
trata de algunos plugins para Gazebo, aunque se va a comprobar como se lanza la pinza de tres dedos en la simulación por si habría alguna dependencia
que hiciera falta.
    Luego, se ha modificado el robot con el que se estaba trabajando; se estaba usando el UR5 y el que hay en el laboratorio es el UR5e. Así, se 
cambió el import de la geometría desde la carpeta de robot_description a robot_e_description. Además, se añadieron al fichero ur5e_robot.urdf.xacro
los ficheros y macros de la pinza para hacerlo igual a lo que se estaba trabajando anteriormente. Este cambio también se realizó en el fichero que
carga los dos robots en el mundo de Gazbeo.
    Por otro lado, se ha intentado incluir la pinza de tres dedos dentro de la simulación aunque por alguna razón los dedos empiezan a temblar y a 
descontrolarse, incluso si se incluye un controlador.
    (4 h) --> 6 / 12 / 22  
    

    A partir del repositorio para poder ejecutar el Phantom Omni en Linux / ROS. En un principio no se pudo ejecutar; se podía calibrar el dispositivo
pero al lanzar el nodo del driver del Phantom saltaba un error, el puerto al que debía de estar conectado no existía según el sistema operativo. Esto
se debía a que se estaba usando el conector con salida Ethernet y este no creaba el puerto en el directorio /dev. Probando con el otro tipo de conector,
el USB, saltaba el mismo fallo. Finalmente se pudo lanzar el programa de los drivers dándole el nombre de "Default Device" y así detectaba el puerto,
por lo que el nodo se podía lanzar.
    Ahora se tenía el Phantom funcionando en Linux, y se podían obtener datos a través de sus topics:
        - /arm/measured_cp: posición cartesiana del efector final
        - /arm/button1 // /arm/button2: botones
        - /arm/servo_cf: topic por el que publicar los wrenches para el feedback de fuerza
    Se realizó un script con el que se recogen datos del measured y se publican en el topic "pose" del controlador de alto nivel del UR5 y se consiguió
mover en simulación.
    A parte del Phantom se ha cambiado el controlador que se estaba utilizando; antes se usaba un PID que aunque seguía bien las trayectorias, había
un poco de oscilación y lentitud en el seguimiento. Por eso se cambió de una interfaz de esfuerzo a una en posición sin especificar PID. Con esto
el robot va a la posición directamente, sin oscilaciones. Aquí se cambia la transmisión (en el archivo de ur.transmission.xacro) de effort a PositionJointInterface
y en el ur5_controller_params.yaml se cambia el tipo de effort a position también.
    (4 h) --> 16 / 12 / 22


    Para el bucle de control del UR5, se ha cambiado el funcionamiento; hasta ahora se publicaba en las articualciones cada vez que llegaba una nueva
posición por el topic /pose, lo que hacía que en el momento en el que llegarán muchas posiciones seguidas, la ejecución se ralentizara (se tienen que
calcular muchas inversas). Para solucionar este problema lo que se hace es en los callbacks se almacena la información y se envía a las articulaciones
en el bucle principal, que se ejecuta acorde a una frecuencia concreta.
    También se ha creado un controlador a parte del que usa una interfaz hardware de posición, un que usa una de esfuerzo con un PID incorporado,
como el que se tenía en un inicio.
    Al final, para obligar al bucle de control a funcionar a cierta frecuencia lo que se hace es tener ejecutar el callback cada vez que pasa un 
intervalo de tiempo específico. Siempre que se envía un dato de posición cartesiana se llama al callback correspondiente, pero su contenido solo se
ejecutará si ha pasado cierto tiempo desde la última ejecución. Así se evita que se ralentice.
    La razón por la cual la librería de ROS del Phantom solo funciona si a la hora de la calibración se llama el dispositivo como "Default Device" es
porque el proyecto de Github define una serie de ficheros de configuración. En el que se lanza por defecto con el nodo de ROS se llama al fichero
sawSensablePhantomDefaultDevice.json, donde se define el espacio de nombres que se va a usar (a la hora de lanzar los topics, el /arm, por si se
tiene más de un Phantom) y el nombre de la configuración, que en este caso es "Default Device". Para lanzarlo con otro nombre habría que crear otro
fichero con una configuración propia y llamarlo como argumento al lanzar el driver del Phantom del proyecto.
    (3 h) --> 21 / 12 / 22



    Para spawnear los dos robots se ha erreglado el ur5_2.launch, más concretamente el ur5e.launch. En él se ha añadido el nodo del controlador
cartesiano, para que se lance uno en cada robot. En ese nodo, se ha añadido la gestión de argumentos de ejecución, ya que solamente llamarlo no es 
suficiente; se tiene que suscribir a los topics con el nombre cambiado, por lo que necesita el espacio de nombres de cada robot. Además, lo topics
en los que publica (como el /pose para mandar consignas cartesianas) también deben ser distintos para cada robot, sino se moverían a la vez ante una
publicación (estarían suscritos al mismo topic). Por eso también se le aplica el cambio de nombre por argumentos con el nombre del robot.
    (1 h) --> 24 / 12 / 22


    Cambié el disco duro externo por una SSD (para ganar en velocidad de ejecución, sobretodo en los primeros momentos después de iniciar sesión) y 
para liberar uno de los puertos USB. Al reinstalar el repositorio junto con todos sus paquetes, surgió el error de que el robot en simulación se caía 
al suelo, como si sus controladores no funcionasen. Para solucionar este problema (o al menos parcialmente) se añadió un botón de Home, en la tecla ESC
mediante la librería pynput.
    (1 h) --> 27 / 12 / 22


    Se reorganizó el proyecto eliminando las partes correspondientes a la práctica 3 y 5 de Teleoperación, de manera que:
        - Se eliminaron las cámaras y sus funciones de callbacks, suscriptores y funcionalidades asociadas
        - Se eliminaron las partes correspondientes al control de velocidad del controlador del robot y del Phantom
        - Se eliminó el feedback visual del Phantom
        - Se eliminaron algunos scripts de pruebas
    Luego, se trabajó para hacer funcional el lanzamiento del controlador con los dos robots se modificaron los ficheros de los controladores para que acepten
parámetros por línea de comandos. De esta manera, el ficheo launch final llama dos veces a un launch dentro de un espacio de nombres ("UR5_1" y "UR5_2"). 
Este último es el encargado de lanzar un robot en Gazebo junto con el robot_state_publisher, joint_states y controladres de cada uno. Además, se lanza los
controladores del robot y su dispositivo Phantom correspondiente, pasando como parámetro el nombre del robot asociado. Internamente estos ficheros procesan 
ese argumento para suscribirse y publicar en los topics. Esto es para que a la hora de la ejecución se generen topics diferentes para cada robot, de ahí el 
espacio de nombres ("/ur5_1/pose" y "/ur5_2/pose" por ejemplo). Así se tiene todo el sistema funcionando.
    Alternativamente, en el launch principal se lanza el nodo para los drivers internos del motor del repositorio cisst-saw. Este nodo debería lanzar los dos
Phantoms a la vez. Para ello, se ha creado un fichero de configuración "sawSensablePhantomUR5.json" donde se especifica con que nombre se deben calibrar cada
uno y el renombre que tienen, llamándose "ur5_1" y "ur5_2" cada uno. Para evitar que el comando lance el fichero de configuración por defecto se debe
especificar la opción '-j' y la ruta del paquete en el que se encuentra el .json (-D -j $(find saw_sensable_phantom_config)/sawSensablePhantomUR5.json). El
-D es para lanzar la interfaz en modo noche.
    Llegados hasta este punto se debería probar el algoritmo en los reales, pues no se sabe como se comportan los drivers de cisst-saw con dos Phantom
conectados al mismo equipo ni como actuarán los ejecutables de calibración en esta situación.
    (3 h) --> 14 / 01 / 23

    
    Se han añadido sensores de par en cada una de las articulaciones del robot, modificando el "ur5e.urdf.xacro" con el plugin de Gazebo libgazebo_ros_ft_sensor.so
que es capaz de simular fuerzas y pares. Aun así, todavía queda comprobar que el sensor está bien colocado y en que dirección expresa esas fuerza y pares, de
manera que interesen según la articulación o si todas están expresadas en la dirección z de su joint, por ejemplo. importante establecer bien el frame de origen
    (1 h) --> 15 / 01 / 23
    
    
    Se ha trasladado la realimentación de la posición de las articulaciones y la cinemática directa al nodo del Phantom así no se interrumpe la ejecución del
nodo del UR5, de manera que este nodo solamente carga las posiciones al robot. El nodo del Phantom sigue teniendo toda la información de las articulaciones
gracias al topic /joint_states y un modelo del ur5e.
    También se está ideando el modo de control bilateral entre los paradigmas posición-posición y fuerza-posición.
    La carpeta que se elimina del proyecto de robotiq es robotiq_3f_gripper_articulated_gazebo_plugins
    (3 h) --> 30 / 01 / 23


    A la hora de insertar la pinza de tres dedos ocurría que al colocarla en el extremo del robot, empezaba a vibrar y oscilar todo el
conjunto. Esto se debía a que el robot está colisionando con la pieza. Para solucionarlo se tomó como referencia algunos foros de Github y 
ROS para desactivar la autoslición del conjunto en el fichero ur_e_description/urdf/ur.gazebo.xacro.
    También se tiene que hacer un controlador específico para la pinza y aumentar las ganancias de la última articulación del robot, la 
del wrist_3.
    
    IMPORTANTE: 
        - Para poder spawnear dos robots cada uno con una pinza desde el sistema de launchs que se tiene (con un launch que se llama desde 
        otro ur5_2 --> ur5e) se usa el argumento '3f' que será true o false en función de si se quiere o no la pinza de tres dedos en el 
        robot. Este argumento condiciona el spawneo del controlador para las dos pinzas y la inclusión de dos ficheros urdf.xacro en el 
        ur5e_upload.launch.
        - Como se menciona anteriormente, se condiciona el fichero ur5e_upload.launch. Se tienen dos ficheros urdf.xacro, uno que modela el
        robot con la pinza de dos dedos y otro para la de tres dedos
        
    Se ha corregido manualmente las transimisiones de la pinza de tres dedos orginal, ya que  al final la original no tenia ningun problema.
Lo único es que se ha añadido la transimsiones en las articulaciones de los dedos (en el urdf de los dedos) y la palma (en el urdf principal).
Se comprobará si se necesita añadir la fricción para el modelado (es lo que lo diferencie del de summer, que en este último los links tienen
coeficientes de fricción asignados).
    
    IMPORTANTE:
        - En la pinza de los tres dedos se tiene que incluir en el ur5e_robot.urdf.xacro con un prefijo, ya que hay dos links con el mismo 
        nombre, el tool0. El controlador está configurado para aceptar las joints solo con el prefijo 'gripper_'.
    (4 h) --> 31 / 01 / 23

    

    Se ha realizado la base del control posición - posición esclavo maestro, de manera que la fuerza es proporcional a la suma del error en posición
y velocidad entre el esclavo y el maestro. La velocidad cartesiana del robot se calcula a partir del desplazamiento cartesiano del mismo, derviándolo
entre el tiempo en el que se toman medidas.
    Se ha creado una especie de máquina de estados que funciona de la siguiente manera:
        - Estado 0: control cartesiano lineal
        - Estado 1: control cartesiano angular (ángulos de Euler)
        - Estado 2: control de la pinza
    Para las transiciones de estado se presiona el botón 1 del lápiz del Phantom.
    También se ha realizado el control de la pinza de dos dedos, de manera que se controle solo en el Estado 2. En este estado, el Phantom restringe 
los movimientos en los ejes X e Y mediante un control proporcional / derivativo, de manera que la pinza se controla subiendo y bajando el Phantom en
el eje Z (esta pinza tiene solo una articulación por lo que solamente requiere un único grado de libertad). Cabe destacar que el operador no puede
llevar el efector final del maestro más abajo del 0 por razones de diseño; la pinza toma valores de 0 a 0.775.
    Para la pinza de tres dedos hay que ver si se controla cada dedo por separado o se controla la pinza entera tal cual.
    Alternativamente, se ha planteado la idea de amortiguar la fuerza aplicada al maestro derivando el error en vez de calcular el error en velocidad
tal cual. También se ha reorganizado el código para que no quede muy farragoso de leer.
    Se ha dejado el cálculo de las velocidades del Phantom y el robot por si fuera necesario en algún momento.
    (3 h) --> 2 / 01 / 23



    La pinza de tres dedos presenta el siguiente comportamiento:
        - Los dedos 1 y 2 se panean a la vez, teniendo una serie de posiciones por defecto
        - Cada dedo se mueve de manera independiente pero sin poder el giro de cada articulación del dedo indivudualmente
    
    Para cumplir con este modelo, se va a hacer uso del plugin de Gazebo roboticsgroup_gazebo_plugins. Se ha añadido las mimic para las 
articulaciones de los dedos y para la de la palma en la parte de los dos dedos. Aun así, surge un problema, y es que el dedo de la articuación se cae
al hacer movimientos y no sigue los comandos de posición correctamente, puede que sea por las ganancias.
    Para hacer el mimic se debe sustituir la transimsion de la articulacion esclava por un plugin de Gazebo y eliminar el controlador.
    
    En cuanto al controlador del robot se ha hecho que se envíen las posiciones articulares en la función donde se calcula la inversa, de manera que 
se hacen en el callback y no todo el rato, para intentar bajar el ancho de banda.

    Se ha incluido el control de la pinza de tres dedos y el feedback de fuerza para la pinza de tres dedos, considerándola como una máquina de estados
secundaria dentro del estado de la pinza. En esta máquina se utiliza el botón 2 para moverse por los subestados. 
    Ese botón solo se usa dentro de ese estado, aunque se podría utilizar para mover hacia atrás en los demás estados de la máquina principal.
    (5 h) --> 5 / 02 / 23



    Se han ajustado las ganancias del controlador del UR5 para que admita la pinza dentro de su configuración. 
    Se ha probado la pinza de tres dedos con las articulaciones clonadas para ver su funcionamiento; las de los dedos funcionan bien aunque la de la
articulación de la palma del dedo 2 está un poco suelta.
    Se ha añadido una mesa para la manipulación de objetos, creando un nuevo fichero para poder spawnear el mundo y la mesa. 
    Por otro lado,se ha descargado los ficheros de Ignacio para la configuración de objetos para los agarres, pero no funcionan bien para incluirlos
en el mundo de Gazebo o no los se añadir bien. Para incluirlos se ha creado un nuevo paquete dentro del proyecto.
    Además, se ha bajado las ganancias de la articulación 3 del robot ya que eran demasiado altas para la de la pinza de 2 dedos, provocaba
oscilaciones. Se deberían obtener nuevos valores para el controlador de esta articulación que fueran válidos para ambos robots. Si no se puediera se
debería hacer un fichero de controlador para cada robot, ya que las pinzas son distintas.
    (7) --> 6 / 02 /23



    Se ha cambiado las coordenadas del feedback de fuerzas; cuando se trabaja con el error del robot se debe hacer el cambio de sistema de referencia.
    Se ha creado otro bucle a parte para hacer la cinemática inversa del robot, de manera que no interrumpa ningún proceso principal con un procedimiento
demasiado pesado. Este nodo se debe lanzar junto con el controlador del UR5 y el spawn de Gazebo
    Se ha probado el bucle de control en el Phantom real y se han obtenido las siguientes conclusiones:
        - Se nota mucho retardo entre la simulación y el control de fuerzas; puede que hacer la separación del control del Phantom en dos nodos no 
    sea una mala idea, ya que así se concentra la ejecución de dos funcionalidades en un solo bucle, sin tantas interrupciones al control de fuerza
    del Phantom por el callback de posiciones.
        - La frecuencia del bucle principal de control del Phantom es crítica; se ha comprobado que según la ganancia proporcional que se indique
    se puede situar alrededor de los 40 o 35 Hz, aunque aun se siguen detectando retrasos
        - A mayor frecuencia mayor estabilidad y aparente retraso se notaba en el funcionamiento del bucle de control y realimentación de fuerzas
        - En el bucle de control de fuerza se ha detectado que la pinza pesa demasiado por lo que provoca que el robot se caiga (creo que es por la)
    pinza, porque el control bilateral en posición refleja las fuerzas externas al operador). Para solucionar este problema se ha añadido una fuerza
    hacia arriba (coordenada 'Y' en el sistema de coordenadas del Phantom) de 0.95 N para compensar la caída (valor determinado experimentalmente).
        - En el funcionamiento normal del bucle de realimentación se anula, en un primer momento, la ganancia derivativa de manera que solo se hace uso
    de la proporcional
        - Parece ser que es importante el buffer de entrada de los subscribers de los topics de los controladores articulares del UR5, pues ayudan a
    mitigar el efecto del retraso
        - Las constantes del feedback de fuerza son muy bajas, ya que se está trabajando con el error en la posicion del robot real y no con el del
    Phantom, por lo que se debe mitigar su efecto al operador para no sentir fuerzas excesivas.

    Se debe trabajar en encontrar una constantes (ganancias, tamaño de buffer, frecuencias, ...) adecuadas al funcionamiento de la aplicación.
    Para lanzar el Phantom con la librería del repositorio de cisst se debe especificar el fichero JSON con el que se quire lanzar, ya que el comando
por defecto y el que lanza el RVIZ utilizan el nombre de "arm", lo que resulta incorrecto para el proyecto.


    IMPORTANTE --> Comprobar si en el controller.py mejora el comportamiento al añadir el feedback de las posiciones, para calcular la cinemática
inversa. Tal y como está ahora se calcula la cinemática inversa a partir de las posiciones del origen del robot.
               --> Mirar también si aumentar la constante de fuerza o aumentar la frecuencia de funcionamiento hace que el brazo no se caiga
               --> Probar también a no tener un intervalo de tiempo en el callback de la posición del Phantom, para ir recogiendo más posiciones
               Puede que sea por esto que no funcione bien el feedback y vaya un poco a tirones cuando se ponían frecuencias altas.

    (4 h) --> 7 / 02 / 23 --> SESIÓN REAL



    Lo que ponía antes de la constante proporcional de fuerza y de la frecuencia no importa, me equivoqué al poner las constantes en el bucle de
control de la fuerza.
    Se ha diversificado el bucle de control del Phantom en otra rama del Gihub; ahora se tiene un nodo que solamente manda comandos de posición a la
controladora del UR5e y computa la posición del Phantom y del robot a partir de esta. Estas posiciones se mandan a el segundo nodo, el nodo del control
de fuerzas, que se encarga de aplicar una serie de fuerzas al operador a partir de las posiciones calculadas por el nodo de posición y la posición
cartesiana del extremo del robot.

    IMPORTANTE: comprobar si funciona primero.
                Luego comprobar que no hay retardo excesivo al hacer el cálculo de la posición en el nodo de posición y luego mandárselo al nodo de 
            fuerza. La otra opción sería tener los dos callbacks asignados a la posición del Phantom, con el mismo código, uno en cada nodo
    (2 h) --> 8 / 02 / 23



    Para spawnear el modelo de los objetos en RVIZ se debe cambiar algunas cosas del model.urdf.xacro de cada uno de los objetos:
        - Primero, para incluir los ficheros .obj se debe colocar la ruta desde el fichero src (desde donde se lanzan el comando de inicio) hasta el
        directorio donde se encuentran los ficheros .obj. La ruta quedaría como package://objects_models/models/002_master_chef_can/textured_simple_reoriented.obj
        - Luego, se debe añadir un link auxiliar ya que RVIZ no admite que los links de referencia (los que se pueden tomar como sistema de referencia 
        para obtener transformadas de los demás) tengan variables de inercia. Por eso es que se añade este link "dummy" junto con una joint fijada al 
        objeto
    Se ha creado un launch para lanzar un objeto en el mundo ya creado. El objeto se puede elegir mediante un argumento de entrada

    PROYECCION: se ha pensado en hacer una especie de interfaz de usuario desde la que lanzar la simulación y más adelante el control del robot real.
Esta interfaz sería la responsable de lanzar la simulación y los objetos que se quieran. En esta aplicación se podría incluir también el calibrado
de los Phantom, llamando a la ejecución de los ejecutables del fabricante. Más adelante se podría incluir la selección de robots o pinzas que se
quieran añadir a cada uno.
    Se ha empezado a hacer la interfaz de usuario para que sea capaz de hasta seleccionar los robots y con que pinza se va a lanzar. La interfaz se
está haciendo con DearPyGui.
    Las funcionalidades de la interfaz son las siguientes:
        - Menú de modo: un menú que selecciona el modo de funcionamiento, es decir, si se quiere usar los robots en simulacion o en el real.
        - Menú de tutoria: activa o desactiva los tutoriales
        - Simulacion: configuración de las opciones de simulación
            - Número de robots
            - Para cada robot:
                - Pinza a enganchar
                - Posición en el mundo
                - nombre
            - Lanzar la simulación: con un botón se lanza la simulación con los parámetros que se hayan especificado por parte del usuario. Para
            hacerlo se hace uso de la API de ROSLAUNCH, que permite ejecutar ficheros .launch dentro de un script de Python. Se esocgió esta opción
            y no la de la librería subprocess porque con este si que se puede anular la ejecución de los ficheros
        - Configuración del Phantom: ejecución de los ficheros de configuración del Phantom. Se ejecutan los ejecutables de configuración y calibración
        del Phantom desde el script de Python mediante la librería "subprocess" (subprocess.Popen) que permite ejecutar comandos en un bash (terminal)
        desde un programa de Python.
    
    Todos los elementos de la GUI tienen una descripción de lo que hacen o su función al pasar por encima el ratón sobre ellos.
    (8 h) --> 9 / 02 / 23



    Se ha conseguido lanzar un fichero .launch con argumentos desde un script de Python utilizando la API de Roslaunch, que las veces anteriores no
permitía enviar argumentos porque no admitía una lista dentro del constructor del objeto que lanza el fichero .launch porque no tienen método "read".
El problema se soluionó usando el ejemplo de lanzar una fichero .launch con un argumento; simplemente se añaden más argumentos a la lista y ya se
puede lanzar. 

    NUEVA FUNCIÓN GUI:
        - Configuración de simulación: al lanzar la simulación se cambia la interfaz de ususario, mostrando nuevas opciones que se pueden realizar
            - Spawnear objetos: se pueden añadir objetos a la simulación, especificando ciertos campos:
                - Nombre del objeto: decide cual objeto añadir dentro de una lista
                - Posición y orientación del objeto
            - Botones de spawn
            - Cierre de la simulación: se apga la simulación y vuelve a la vista de configuración

    Para cambiar la orientación de un elemento en Gazbeo al lanzar la simulación, en el nodo pkg="gazebo_ros" type="spawn_model" especificar las
opciones "-R", "-P" y "-Y" para las rotaciones roll, pitch y yaw correspondientes
    (3.5 h) --> 10 / 02 / 23



    Se ha añadido publisher de la posición de las pinzas según el tipo de pinza en el nodo de la posición cartesiana del robot. 
    En el nodo de control del Phantom se ha añadido el feedback para la pinza y se ha cambiado el sistema de máquina de estados de la pinza; ahora 
solo se tienen dos sub - estados, uno para mover los tres dedos según los ejes XYZ del Phantom y el siguiente estado para la articulación de la palma
de los dedos.
    (2 h) --> 11 / 02 / 23
    
    

    En el bucle de control del Phantom se ha configurado para que vaya a menor frecuencia (menos retardos) y también se han configurado las ganancias
de manera que mientras se están enviando posiciones al robot no se ejerca ninguna fuerza sobre el usuario. La única fuerza que aplica es un campo de
fuerza hacia arriba, de manera que si el operador suelta el Phantom este mantenga la posición.
    Todos los bucles de todos los programas están configurados para funcionar a la misma frecuencia.

    PROYECCION:
        - Para poder aplicar el feedback de fuerzas al operador se tiene que comprobar si el robot ha chocado con algún obstáculo. Para hacer esta
        comprobaión se puede aplicar dos enfoques; comprobar el error que se comete y determinar un umbral o calcular la fuerza sobre el extremo a
        partir de los pares articulares.
    
    Se ha establecido la articulaciones de la palma como fijas de momento, para que no den problemas a la hora de moverla y tiemble toda la pinza.
Esta articulación da problemas porque parece que no está del todo enganchada a la pinza, lo que provoca que se mueva suelta, sin ningun comando
    (3.5h) --> 14 / 02 / 23 --> SESIÓN REAL



    Se ha creado la funcionalidad para medir la fuerza en el extremo a partir de la cinemática directa, esto es, a partir de los pares medidos en las
articulaciones se computa la fuerza cartesiana que sentiría en el extremo. Esto se hace multiplicando el vector de pares por la matriz jacobiana.
    Estos valores se deberían utilizar para detectar cuando se ha chocado con un elemento, estableciendo umbrales o haciendo derivadas y observando cuando
la función tiene picos progresivos de fuerza para asi determinar el momento del contacto y aplicar fuerzas al operador en consecuencia.

    En cuanto a la interfaz, se ha cambiado la manera en la que se selecciona la posición y orientación de los objetos para importarlos al mundo.
En vez de tener campos de texto se utilizan sliders, así se puede hacer la selección de atributos más fácilmente. También se ha añadido un texto que 
indica si los sliders son de posición o de orientación. El texto de indicación cambia según el objeto seleccionado
    (2 h) --> 15 / 02 / 23



    Se ha creado el topic por el cual se envian los mensajes de fuerza desde el fichero que controla el estado del robot (cart_pos) al controlador
del Phantom, de manera que se detecten picos de fuerza y se pueda actuar en consecuencia, aplicando una fuerza en el operador maestro.
    (1 h) --> 16 / 02 / 23
    


    Se ha cambiado el modo de funcionamiento de la orientación, ahora la tres coordenadas correspondientes a los ángulos de 
Euler del robot se controlan mediante control articular. El control es más sencillo (creo yo) y resuelve un problema que se 
tenía desde el inicio; los errores en la planificación de la cinemática inversa, sobretodo en la rotación en Y (pitch), que
actuaba más articulaciones de las que debía, provocando un movimiento erróeneo (se movía no solo en pitch sino también en 
yaw). 
    Para realizarlo se ha añadido un flag en el controlador de alto nivel del robot, de manera que si se está moviendo en 
posición se hace en coordenadas cartesianas, calculando la inversa. Al cambiar de modo (presionando el botón del Phantom),
se cambia el flag, controlando directamente las articulaciones independientes, una por cada eje en el espacio cartesiano de
trabajo del maestro. Esta funcionalidad ya estaba implementada en el Phantom, cambiando los modos de posición, orientación y 
pinza
    El controlador de momento está cambiado, junto con el programa de prueba con los sliders, faltaría cambiar el fichero
de control del Phantom, de manera que al presionar un botón cambiar el modo
    (3.5 h) --> 19 / 02 / 23



    Se ha creado un topic para que la interfaz de usuario muestre si se está moviendo el Phantom para 
llegar a una posición de reposo (un cambio). Esto se hace enviando el estado en el que se encuentra la 
máquina de estados. En la interfaz se mantiene una copia de la variable del estado, de manera que muestra
en que sistema se está moviendo o si está habiendo un cambio. Para indicar que deja de haber cambio se 
envía un '-1' por el topic.
    Se ha adecuado el sistema para que se mueva en orientación con las articulaciones de la muñeca en vez
de los ángulos de Euler. Lo único que se ha hecho ha sido cambiar en el cart_pos a la hora de enviar la
orientación en RPY, se envían los valores articulares. Además, también se envían los pares de las 
articulaciones, para el feedback de fuerzas, que también se adecua a este formato.
    Sin embargo, también se ha comprobado que si se pone el 'order='yxz'' en la cinemática directa y en las 
transformadas, así como en las matrices de rotación, la orientación es correcta, moviéndose adecuadamente
en los ángulos de Euler (aun así están cambiados, como ya ocurría con el 'order='xyz'')
    (2.5 h) --> 21 / 02 / 23



    Se ha aumentado la velocidad de las articulaciones en el fichero .urdf.xacro del UR5 para que a la hora de
la teleoperación llegue a mayores velocidades y no se produzcan tantos retardos.
    Se ha creado un topic 'change' para que al hacer un cambio en el funcionamiento del robot se indique hacia que
estado se está moviendo el sistema y en cual modo se está moviendo.
    Se ha disminuido el buffer de entrada de los publishers articulares del controlador, ya que así si se realizan
movimientos suaves se hace correctamente (se envía todo el rato desde el phantom) y si se interrumpen movimientos,
no hace la trayectoria entera, lo que suple algunos retardos.
    (4 h) --> 01 / 03 / 23



    Se ha implementado un filtro de mediana en el controlador cartesiano del robot a la hora de mandar
las consignas articulares al robot, de manera que el ruido en la entrada no influya en el movimiento del
robot, ya que la entrada del Phantom es muy ruidosa.
    (3 h) --> 03 / 03 / 23




INSTALL sudo apt-get install ros-noetic-soem
INSTALL sudo apt-get install ros-noetic-moveit
INSTALL sudo apt-get install ros-noetic-socketcat-interface
INSTALL sudo apt-get install ros-noetic-ros-control
INSTALL sudo apt-get install ros-noetic-ros-controllers




--------------------------------------------------------------------------------------------------
                        ESTADO DEL ARTE



Links:
    - Shadow Space Modeling and Task Planning for Collision-free Cooperation of Dual Manipulators for Planar Task: https://link.springer.com/article/10.1007/s12555-018-0236-1
        · Método para la planificación de trayectorias con dos brazos robóticis
        · Evasión de colisiones
    - Teleoperación de un brazo robot Kinova MICO2 a través de un dispositivo Omni Bundle: https://rua.ua.es/dspace/handle/10045/77712
        · Trabajo de teleoperación de un Kinova
        · Estructura de trabajo
        · Idea para el control de fuerzas
        · Cerrar bucles de control PID
    - Experimental evaluation of magnified haptic feedback for robot-assisted needle insertion and palpation: https://onlinelibrary.wiley.com/doi/full/10.1002/rcs.1809?casa_token=lyiuUkXMm0sAAAAA%3Ad-5IaaZF66xAu0GZ9IcLRt_D_iwemnZsYkaf0n5Th22okqcmDOgaXHOSLjtzXJ_5tHaKubY4VaEZfeE
        · Teleoperación médica
        · Robótica compartida
        · Pasividad
    - KONTUR-2: Force-feedback teleoperation from the international space station: https://ieeexplore.ieee.org/document/7487246
        · Feedback de fuerza
        · Teleoperación
        · NO SE PUEDE ACCEDER AL ATÍCULO
    - Shared-Autonomy Control for Intuitive Bimanual Tele-Manipulation: https://ieeexplore.ieee.org/abstract/document/8625047?casa_token=GRWgO5RjOaoAAAAA:uBFHm_GJExJFxh1HuIkK3LVG6tvOjpasat0aNddHPd_1SOPrsfwR7y2DO-87KquuWwljS4sfyg
        · Control de dos roots con los dos brazos
        · Sensores sEMG para reconocimiento de gestos de mano
        · IMU para obtención de posiciones y orientaciones
    - Improvement of operability in remote robot control with force feedback: https://ieeexplore.ieee.org/abstract/document/7398509?casa_token=SWpv-FKCtt8AAAAA:uoZ4i2dH_YJYuxX8IXyxH61l8WP3BkRhF9v7yDMJru0gpXtbrntqQd84V8haMux4aqOW1t2Eig
        · Realimentación de esfuerzos
        · Mejora de la calidad de la manipulación
        · Medidas de la mejora
        · Métodos de control de fuerzas
    - Force feedback based gripper control on a robotic arm: https://www.researchgate.net/publication/307435905_Force_feedback_based_gripper_control_on_a_robotic_arm
        · Realimenración de esfuerzos
    - Haptic Feedback in Robot-Assisted Minimally Invasive Surgery: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2701448/
        · Robótica asistiva en operaciones
        · Realimentación de esfuerzos y realimentación táctil
        · Háptica


Conceptos interesantes a investigar:
    - Pasividad:
        · https://web.mat.upc.edu/carles.batlle/Passive%20Control%20Theory%20I.pdf
        · https://www3.nd.edu/~lemmon/courses/ee580/lectures/chapter10.pdf
            - Libros que explican que es la pasividad
    - Retroalimentación de fuerzas
        · 
    - Teleoperación
    - Háptica
        · Kinestesia
        · Táctil
    - Robótica compartida / control compartido
    - Campos de aplicación de la teleoperación, retroalimentación de fuerzas, control compartido, ...
--------------------------------------------------------------------------------------------------




---------------------- Packages-UR Drivers -----------------
git clone https://github.com/UniversalRobots/Universal_Robots_ROS_Driver.git src/Universal_Robots_ROS_Driver
 sudo apt install industrial-robot-status-interface
 sudo apt install ros-noetic-industrial-robot-status-interface
 sudo apt install ros-noetic-scaled-joint-trajectory-controller
 sudo apt install ros-noetic-speed-scaling-interface
 sudo apt install ros-noetic-speed-scaling-state-controller
 sudo apt install ros-noetic-ur-msgs
 sudo apt install ros-noetic-pass-through-controllers
 sudo apt install ros-noetic-ur-client-library
 

 //Instalar MoveIt
 sudo apt install ros-noetic-moveit-core
 sudo apt install ros-noetic-moveit-ros-move-group
 sudo apt install ros-noetic-moveit 
 
 // Instalar ROS Control
 sudo apt-get install ros-noetic-ros-control ros-noetic-ros-controllers
 
 // Instalar Robotic Toolbox
  pip3 install roboticstoolbox-python

// Instalar RobotIQ paquetes:
  sudo apt-get install ros-noetic-socketcan-interface
  sudo apt-get install ros-noetic-soem

  - Simulacion en RVIZ
 sudo apt-get install ros-noetic-moveit-visual-tools
 sudo apt-get install ros-noetic-moveit-ros-visualization

// Instalar controladores de ROS
  - sudo apt-get install ros-noetic-ros-controllers --> no creo que sea necesario

// Phantom:
  - sudo apt-get install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev
  - sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev
  - sudo apt-get install libncurses5 libncurses5:i386

  - Cambios
   - + ../ur_gazebo/controller/ur5_controller_params.yaml: archivo YAML con los parámetros de las ganancias de los controladores PID de cada articulación
   - M ../ur_descriptions/urdf/ur.transmission.xacro: en este archivo están las transmisiones de las articulaciones (PositionJointInterface) se cambia el ${hw_transmission} por EffortJointInterface
   - M ../ur_gazebo/launch/ur5.launch: 
   	· se comentan las líneas del controlador por defecto y se añade el controlador PID de cada articulación con su spawner
  	· se añade al spawn del modelo la posición del shulder_lift_joint y elbow_joint
  	· se cambia el argumento paused a true --> la simluación empieza parada, al luego activarla el robot se coloca en la posición indicada en 	   los argumentos del spawner
   - + ../ur_description/urdf/ur5_robotiq85_gripper.urdf.xacro: archivo URDF para lanzar el robot UR5 joint_limited con el gripper de ROBOTIQ 85 (demo) (UNUSED)
   - + robotiq: proyecto con archivos URDF del gripper de ROBOTIQ (solo el 85)
   - M ../robotiq/robotiq_arg2f.xacro: se añade un parámetro "parent". Se añade una joint en la macro de "robotiq_arg2f_base_link" con el parent
   del parámetro y el base_link del propio link definido en la macro
   - M ../robotiq/robotiq_2f_140_gripper_visualization/urdf/robotiq_arg2f_140_model_macro.xacro: se define el parámetro de "parent" en la macro "robotiq_arg2f_140". Se definen los comandos para activar la auto - colisión de los modelados.
   - M ../robotiq/robotiq_2f_140_gripper_visualization/urdf/robotiq_arg2f_140_model.xacro: se añade el parámetro "parent" a la macro "robotiq_arg2f_140"
   - M ../robotiq/robotiq_2f_140_gripper_visualization/urdf/robotiq_arg2f_transmission.xacro: Se añadieron las "hardwareInterface" de cada una de las articulaciones
   - M ../robotiq/robotiq_2f_140_gripper_visualization/urdf/robotiq_arg2f_transmission.xacro: se añadió el plugin de robotiq_group (suprime el de
   arribe)
   - M ../robotiq/robotiq_2f_140_gripper_visualization/urdf/robotiq_arg2f_140_model_macro.xacro: se anulan las autocolisiones
   - M ../universal_robots/ur_description/urdf/ur5_robot.launch: se incluye el archivo .xacro "robotiq_arg2f_140_model_macro.xacro"
   - M ../universal_robots/ur_gazebo/launch/ur5_robot.launch: se incluye el controlador de la pinza
   - + ../universal_robots/ur_gazebo/controllers/arg2f_140_controller.yaml: Se ha creado un controlador para las articulaciones de la pinza de
   RobotIQ
   - M ../universal_robots/ur_gazebo/ur5.launch: se modifica para que admita la llamada desde otro archivo launch con varios argumentos y parámetros
   para seleccionar los nombres. También se eliminan los spawns de gazebo y el mundo
   - + ../unversal_robots/ur_gazebo/launch/ur5_2.launch: launch para dos robots. Se ejecutan los spawns del mundo y gazebo.
   - + ../unversal_robots/ur_gazebo/launch/ur5_.launch: launch para lanzar un solo robot UR5. También se puede lanzar con el controlador en bucle
   cerrado de velocidad
   - + ../universal_robots/ur_gazebo/controller/ur5_vel_controller.yaml: ganancias PID para el control de velocidad, con otro tipo de controlador 
   (effort_controoler/JointVelocityController)
   - + ../vel: paquete para el control de velocidad en bucle cerrado
   - + ../ur_e_description/urdf/ur5e.urdf.xacro: se añade al final los sensores de par
   - - ../robotiq: la carpeta que se elimina del robotiq_3f es la robotiq_3f_gripper_articulated_gazebo_plugins
   - M ../ur_e_gazebo/urdf/ur.gazebo.xacro: configurar el wrist_3_link y el ee_link para que no auto colisionen
   - M ../ur_e_description/ur5e_upload: se cambia el argumento de 'limited' al de '3f' para seleccionar que pinza adherir al robot
   - M ../robotiq/robotiq_3f_gripper_visualization/robotiq-3f-gripper_articulated_macro.xacro && robotiq-3f-gripper_finger_articulated_macro.xacro:
   se han añadido las transmisiones a las articulaciones de los dedos y la palma
        También se han añadido los plugin del roboticsgroup_gazebo_plugins para copiar el movimiento de las articulaciones, el tag mimic
   - M ../robotiq/robotiq_3f_gripper_visualization/robotiq.transmission.xacro: lo de arriba; sustituir las transmisiones de las articulaciones 2 y 3
   por el plugin para el mimic 


  - Páginas Web:
    - Tutorial ROS Control: https://roboticscasual.com/ros-tutorial-control-the-ur5-robot-with-ros_control-tuning-a-pid-controller/
    - Python Robotic Toolbox (instalar): https://pypi.org/project/roboticstoolbox-python/
    - Python Robotic Toolbox (DOC): https://petercorke.github.io/robotics-toolbox-python/intro.html
    - UR5 with gripper Tutorial: https://roboticscasual.com/ros-tutorial-how-to-create-a-moveit-config-for-the-ur5-and-a-gripper/ (UNSUSED)
    - UR5 with gripper (summer_repository): https://www.youtube.com/watch?v=4zsZUm7T3LA
    - ROS UR Drivers: https://github.com/UniversalRobots/Universal_Robots_ROS_Driver
    - Universal Robots Repo: https://github.com/ros-industrial/universal_robot
    - RobotIQ gripper Mimic (Forun): https://github.com/ros-industrial/robotiq/issues/150
    - roboticsgroup_gazebo_plugins: https://github.com/roboticsgroup/roboticsgroup_gazebo_plugins
    - install libncurses5-dev: https://zoomadmin.com/HowToInstall/UbuntuPackage/libncurses5-dev
    - OpenHaptics for Linux: https://support.3dsystems.com/s/article/OpenHaptics-for-Linux-Developer-Edition-v34?language=en_US
    - Tutorial instalación drivers Phantom Omni: https://s3.amazonaws.com/dl.3dsystems.com/binaries/Sensable/Linux/Installation+Instructions_2022.
    pdf
    - Repositorio jhu (Phantom Omni en ROS):  https://github.com/jhu-saw/sawSensablePhantom
    - Repositorio de un launch de la pinza (intuituve_computing): https://github.com/intuitivecomputing/ur5_with_robotiq_gripper
    - UR5e DH: https://www.universal-robots.com/articles/ur/application-installation/dh-parameters-for-calculations-of-kinematics-and-dynamics/
    - Sensor de fuerzas: https://answers.ros.org/question/243173/interpretation-of-forcetorque-sensor-using-gazebo_ros_ft_sensor-plugin/
    - Sensor de fuerzas (oficial): http://wiki.ros.org/force_torque_sensor_controller
    - Repositorio para la Robotiq 3f gripper (referencia y guia): https://github.com/KTigerFIre/UR5_robotiq
    - Repositorio de los modelos de la mesa: https://github.com/osrf/gazebo_models
    - Referencia de ROSLAUNCH para Python: http://wiki.ros.org/roslaunch/API%20Usage
    - DearPyGui GUI: https://dearpygui.readthedocs.io/en/latest/documentation/item-value.html
    - Subprocess documentation: https://docs.python.org/3/library/subprocess.html

  - Conexión con Matlab:
    - Definir en el Linux ROS_IP=mi_ip y ROS_MASTER_URI=http://mi_ip:11311


